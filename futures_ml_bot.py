import os
import json
import time
import random
from typing import Dict, Any, List

# ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã¨æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
import pandas as pd
import numpy as np
from sklearn.preprocessing import MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from joblib import dump, load

# å¤–éƒ¨API (CoinGeckoã®Simulated APIã¨ã—ã¦æ‰±ã†)
# NOTE: å®Ÿéš›ã®å¤–éƒ¨APIã‚³ãƒ¼ãƒ«ã¯ã€ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã¨å®Ÿè¡Œç’°å¢ƒã®åˆ¶ç´„ä¸Šã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨ã—ã¦è¨˜è¿°ã—ã¾ã™ã€‚
# å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€requestsãƒ©ã‚¤ãƒ–ãƒ©ãƒªãªã©ã‚’ä½¿ç”¨ã—ã¦APIã‚’å©ã„ã¦ãã ã•ã„ã€‚
# ã“ã“ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿å–å¾—å¤±æ•—æ™‚ã®å‡¦ç†ã‚’å¼·èª¿ã—ã¾ã™ã€‚

# --- å®šæ•°è¨­å®š ---
REPORT_FILENAME = 'latest_report.json'
MODEL_FILENAME = 'futures_predictor.joblib'
FALLBACK_FILENAME = 'fallback_data.csv'
DAYS_LOOKBACK = 900  # éå»ç´„2.5å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨
HORIZON = 5          # äºˆæ¸¬ã™ã‚‹æ—¥æ•° (5æ—¥å¾Œçµ‚å€¤ã‚’äºˆæ¸¬)

# --- ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤– ---
class DataFetchError(Exception):
    """ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆã®ã‚«ã‚¹ã‚¿ãƒ ä¾‹å¤–"""
    pass

# --- ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ ---
class FuturesMLBot:
    """
    å…ˆç‰©å¸‚å ´ã®ä¾¡æ ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã€MLãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã€äºˆæ¸¬ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹ã€‚
    ãƒ‡ãƒ¼ã‚¿å–å¾—ã®å …ç‰¢æ€§ã‚’ç¢ºä¿ã™ã‚‹ãŸã‚ã€APIå¤±æ•—æ™‚ã«ã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹ã€‚
    """
    
    def __init__(self):
        """ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹åˆæœŸåŒ–æ™‚ã«ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚"""
        self.scaler = MinMaxScaler(feature_range=(0, 1))
        print("ğŸ¤– FuturesMLBotåˆæœŸåŒ–å®Œäº†ã€‚")

    # --- 1. ãƒ‡ãƒ¼ã‚¿å–å¾— (å …ç‰¢æ€§ã‚’è€ƒæ…®) ---

    def _simulate_api_fetch(self, days: int) -> pd.DataFrame:
        """
        CoinGecko APIã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚
        ãƒ©ãƒ³ãƒ€ãƒ ã«å¤±æ•—ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚
        """
        print(f"ğŸ“¡ APIã‹ã‚‰éå» {days} æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è©¦è¡Œä¸­...")
        
        # ç¨€ã«APIãŒå¤±æ•—ã™ã‚‹çŠ¶æ³ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ (æœ¬ç•ªç’°å¢ƒã§ã¯ã“ã®ãƒ©ãƒ³ãƒ€ãƒ å¤±æ•—ã¯ä¸è¦)
        if random.random() < 0.05: # 5%ã®ç¢ºç‡ã§å¤±æ•—
            raise DataFetchError("CoinGecko APIã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã¾ãŸã¯ã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ã€‚")

        # æˆåŠŸã—ãŸã¨ä»®å®šã—ã¦ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆ
        # NOTE: å®Ÿéš›ã®ãƒ‡ãƒ¼ã‚¿ã¯APIãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‹ã‚‰ç”Ÿæˆã•ã‚Œã¾ã™ã€‚
        
        start_date = datetime.now() - timedelta(days=days)
        date_range = pd.date_range(start=start_date, periods=days, freq='D')
        
        # ç°¡ç•¥åŒ–ã®ãŸã‚ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜æ§‹é€ ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
        data = {
            'Date': date_range,
            'Close': np.cumsum(np.random.normal(0, 10, days)) + 1000,
            'Volume': np.random.randint(10000, 50000, days)
        }
        df = pd.DataFrame(data).set_index('Date')
        df['Close'] = df['Close'].round(2)
        df['Volume'] = df['Volume'].astype(int)
        
        return df

    def _load_fallback_data(self) -> pd.DataFrame:
        """
        ãƒ­ãƒ¼ã‚«ãƒ«ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚
        """
        print(f"ğŸ“‚ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ ({FALLBACK_FILENAME}) ã‚’èª­ã¿è¾¼ã¿ä¸­...")
        if not os.path.exists(FALLBACK_FILENAME):
            print(f"ğŸš¨ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {FALLBACK_FILENAME}")
            return pd.DataFrame()
            
        try:
            # Dateã‚’ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦ãƒ‘ãƒ¼ã‚¹ã—ã¦èª­ã¿è¾¼ã‚€
            df = pd.read_csv(FALLBACK_FILENAME, index_col='Date', parse_dates=True)
            # å¿…è¦ãªåˆ— 'Close' ã¨ 'Volume' ãŒã‚ã‚‹ã‹ç¢ºèª
            if 'Close' not in df.columns or 'Volume' not in df.columns:
                 print("ğŸš¨ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ•ã‚¡ã‚¤ãƒ«ã«å¿…è¦ãªåˆ—(Close, Volume)ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                 return pd.DataFrame()
            print(f"âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚è¡Œæ•°: {len(df)}")
            return df
        except Exception as e:
            print(f"ğŸš¨ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            return pd.DataFrame()

    def fetch_ohlcv_data(self, days: int) -> pd.DataFrame:
        """
        ä¸»è¦ãªãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ¡ã‚½ãƒƒãƒ‰ã€‚APIã‚’è©¦è¡Œã—ã€å¤±æ•—ã—ãŸå ´åˆã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«åˆ‡ã‚Šæ›¿ãˆã‚‹ã€‚
        """
        try:
            # 1. APIã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è©¦ã¿ã‚‹
            df = self._simulate_api_fetch(days)
            if df.empty:
                raise DataFetchError("APIã‹ã‚‰ç©ºã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚")
            print("âœ… APIãƒ‡ãƒ¼ã‚¿å–å¾—æˆåŠŸã€‚")
            return df
            
        except DataFetchError as e:
            print(f"âš ï¸ ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e} -> ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
            # 2. å¤±æ•—ã—ãŸå ´åˆã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€
            df_fallback = self._load_fallback_data()
            
            if df_fallback.empty:
                print("ğŸš¨ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚‚ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
                return pd.DataFrame() # æœ€çµ‚çš„ã«ç©ºã®DataFrameã‚’è¿”ã™

            # éå»DAYS_LOOKBACKæ—¥æ•°ã«ãƒ‡ãƒ¼ã‚¿ã‚’çµã‚Šè¾¼ã‚€
            if len(df_fallback) > days:
                df_fallback = df_fallback.iloc[-days:]
                
            print("âœ… ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return df_fallback
        except Exception as e:
            print(f"ğŸš¨ äºˆæœŸã›ã¬ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
            return pd.DataFrame()
    
    # --- 2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã¨å­¦ç¿’ ---

    def _create_features(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        ç§»å‹•å¹³å‡ç·šã‚„å‡ºæ¥é«˜ã®ãƒ©ã‚°ãªã©ã€MLãƒ¢ãƒ‡ãƒ«ç”¨ã®ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚
        """
        df_copy = df.copy()

        # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå¤‰æ•° (æœªæ¥ã®çµ‚å€¤)
        # T+HORIZON æ—¥å¾Œã®çµ‚å€¤ã‚’äºˆæ¸¬ã™ã‚‹
        df_copy['Target'] = df_copy['Close'].shift(-HORIZON) 

        # ç‰¹å¾´é‡: çŸ­æœŸãƒ»é•·æœŸç§»å‹•å¹³å‡ç·š
        df_copy['MA_7'] = df_copy['Close'].rolling(window=7).mean()
        df_copy['MA_30'] = df_copy['Close'].rolling(window=30).mean()
        
        # ç‰¹å¾´é‡: å‡ºæ¥é«˜ã®ãƒ©ã‚°
        df_copy['Volume_Lag_1'] = df_copy['Volume'].shift(1)
        
        # NaNè¡Œã‚’å‰Šé™¤ (ç§»å‹•å¹³å‡ç·šè¨ˆç®—ã«å¿…è¦ãªéå»ãƒ‡ãƒ¼ã‚¿ãŒãªã„è¡Œ)
        df_copy.dropna(inplace=True)
        
        return df_copy
        
    def train_and_save_model(self, df: pd.DataFrame):
        """
        ãƒªãƒƒã‚¸å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã—ã€ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã—ã¾ã™ã€‚
        ãƒ¢ãƒ‡ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã€ã¾ãŸã¯å®šæœŸçš„ãªå†å­¦ç¿’ãŒå¿…è¦ãªå ´åˆã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚
        """
        df_features = self._create_features(df)
        if df_features.empty:
            print("ğŸš¨ ç‰¹å¾´é‡ç”Ÿæˆå¾Œã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒç©ºã«ãªã‚Šã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return

        # ç‰¹å¾´é‡ (X) ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ (y) ã‚’å®šç¾©
        X = df_features[['Close', 'MA_7', 'MA_30', 'Volume_Lag_1']].values
        y = df_features['Target'].values

        # ãƒ‡ãƒ¼ã‚¿ã®æ­£è¦åŒ–
        X_scaled = self.scaler.fit_transform(X) # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ãƒ•ã‚£ãƒƒãƒˆ

        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ (ãƒªãƒƒã‚¸å›å¸°ã‚’ä½¿ç”¨)
        # NOTE: å®Ÿéš›ã®äºˆæ¸¬ã§ã¯ã€ã‚ˆã‚Šé«˜åº¦ãªãƒ¢ãƒ‡ãƒ«(LGBM, ARIMAãªã©)ã‚’ä½¿ç”¨ã™ã‚‹ã“ã¨ãŒæ¨å¥¨ã•ã‚Œã¾ã™ã€‚
        model = Ridge(alpha=1.0)
        model.fit(X_scaled, y)
        
        # ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä¿å­˜
        try:
            dump(model, MODEL_FILENAME)
            # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã¯ã€ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬æ™‚ã«å¿…è¦ãªã®ã§ã€ã“ã“ã§ã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼è‡ªä½“ã‚’ä¿å­˜ã™ã‚‹ã®ã§ã¯ãªãã€
            # self.scalerã¨ã—ã¦ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã«ä¿æŒã—ç¶šã‘ã¾ã™ã€‚
            print(f"âœ… MLãƒ¢ãƒ‡ãƒ«ã‚’ {MODEL_FILENAME} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            print(f"ğŸš¨ ãƒ¢ãƒ‡ãƒ«ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # --- 3. äºˆæ¸¬ã¨ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ ---

    def _load_model(self) -> Any:
        """
        ä¿å­˜ã•ã‚ŒãŸMLãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚å­˜åœ¨ã—ãªã„å ´åˆã¯Noneã‚’è¿”ã—ã¾ã™ã€‚
        """
        if os.path.exists(MODEL_FILENAME):
            try:
                model = load(MODEL_FILENAME)
                print(f"âœ… MLãƒ¢ãƒ‡ãƒ«ã‚’ {MODEL_FILENAME} ã‹ã‚‰ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
                return model
            except Exception as e:
                print(f"ğŸš¨ ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
                return None
        else:
            print(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ« {MODEL_FILENAME} ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å­¦ç¿’ãŒå¿…è¦ã§ã™ã€‚")
            return None

    def fetch_advanced_metrics(self) -> Dict[str, Any]:
        """
        é«˜åº¦ãªæŒ‡æ¨™ (ãƒ•ã‚¡ãƒ³ãƒ€ãƒ¡ãƒ³ã‚¿ãƒ«ã‚ºã€ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆãªã©) ã®å–å¾—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã—ã¾ã™ã€‚
        """
        # NOTE: å®Ÿéš›ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ãƒ‹ãƒ¥ãƒ¼ã‚¹APIã‚„ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒ¡ãƒ‡ã‚£ã‚¢APIãªã©ã‹ã‚‰å–å¾—ã—ã¾ã™ã€‚
        metrics = {
            "market_sentiment": random.choice(["Bullish", "Neutral", "Bearish"]),
            "fear_greed_index": random.randint(10, 90),
            "open_interest_change": round(random.uniform(-5.0, 5.0), 2),
            "economic_data_impact": random.choice(["Low", "Medium", "High"])
        }
        return metrics

    def predict_and_report(self, df: pd.DataFrame, advanced_data: Dict[str, Any]):
        """
        æœ€æ–°ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦äºˆæ¸¬ã‚’è¡Œã„ã€çµæœã‚’JSONãƒ¬ãƒãƒ¼ãƒˆã¨ã—ã¦ä¿å­˜ã—ã¾ã™ã€‚
        """
        model = self._load_model()
        if model is None:
            print("ğŸš¨ äºˆæ¸¬ã‚’è¡Œã†ãŸã‚ã®ãƒ¢ãƒ‡ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return
            
        df_features = self._create_features(df)
        if df_features.empty:
            print("ğŸš¨ äºˆæ¸¬ã‚’è¡Œã†ãŸã‚ã®ç‰¹å¾´é‡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚äºˆæ¸¬ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ã€‚")
            return

        # æœ€æ–°æ—¥ã®ãƒ‡ãƒ¼ã‚¿ (df_featuresã®æœ€å¾Œã®è¡Œ) ã‚’äºˆæ¸¬ã«ä½¿ç”¨
        latest_data = df_features.iloc[[-1]] 
        
        # äºˆæ¸¬ã«ä½¿ç”¨ã™ã‚‹ç‰¹å¾´é‡ã‚’æŠ½å‡º
        X_latest = latest_data[['Close', 'MA_7', 'MA_30', 'Volume_Lag_1']].values
        
        # ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚° (å­¦ç¿’æ™‚ã¨åŒã˜ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä½¿ç”¨)
        # NOTE: ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã¯ train_and_save_model ã§ fit_transform ã•ã‚Œã¦ã„ã‚‹
        try:
            X_latest_scaled = self.scaler.transform(X_latest) 
        except Exception as e:
            print(f"ğŸš¨ ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼å¤‰æ›ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚ãƒ¢ãƒ‡ãƒ«ã®å†å­¦ç¿’ãŒå¿…è¦ã§ã™ã€‚: {e}")
            return

        # äºˆæ¸¬ã®å®Ÿè¡Œ
        predicted_close_price = model.predict(X_latest_scaled)[0]
        
        # æœ€æ–°ã®çµ‚å€¤ã¨äºˆæ¸¬å€¤ã®æ¯”è¼ƒ
        current_close = latest_data['Close'].iloc[0]
        prediction_change = ((predicted_close_price - current_close) / current_close) * 100
        
        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ—¥
        report_date = datetime.now().strftime('%Y-%m-%d %H:%M:%S JST')
        
        # äºˆæ¸¬æ–¹å‘ã®æ±ºå®š
        if prediction_change > 0.5:
            direction = "ä¸Šæ˜‡ãƒˆãƒ¬ãƒ³ãƒ‰ç¶™ç¶š (Bullish)"
            action = "ç©æ¥µçš„ãªè²·ã„å¢—ã—"
        elif prediction_change < -0.5:
            direction = "ä¸‹é™ãƒˆãƒ¬ãƒ³ãƒ‰è­¦æˆ’ (Bearish)"
            action = "åˆ©ç¢ºã¾ãŸã¯ç©ºå£²ã‚Šæ¤œè¨"
        else:
            direction = "ãƒ¬ãƒ³ã‚¸ç›¸å ´ã¾ãŸã¯èª¿æ•´å±€é¢ (Neutral)"
            action = "æ§˜å­è¦‹ã¾ãŸã¯çŸ­æœŸãƒˆãƒ¬ãƒ¼ãƒ‰"
            
        # äºˆæ¸¬çµæœã‚’JSONå½¢å¼ã§æ§‹é€ åŒ–
        report = {
            "report_time": report_date,
            "prediction_horizon_days": HORIZON,
            "current_close_price": round(current_close, 2),
            "predicted_close_price": round(predicted_close_price, 2),
            "predicted_change_percent": round(prediction_change, 2),
            "prediction_direction": direction,
            "recommended_action": action,
            "advanced_metrics": advanced_data, # é«˜åº¦ãªæŒ‡æ¨™ã‚’å«ã‚ã‚‹
            "data_source": "API (ã¾ãŸã¯ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨)", # ã©ã¡ã‚‰ãŒä½¿ã‚ã‚ŒãŸã‹ã‚’ç¤ºå”†
            "chart_data": self._prepare_chart_data(df) # ãƒãƒ£ãƒ¼ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿
        }

        # JSONãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        try:
            with open(REPORT_FILENAME, 'w', encoding='utf-8') as f:
                json.dump(report, f, ensure_ascii=False, indent=4)
            print(f"âœ… äºˆæ¸¬ãƒ¬ãƒãƒ¼ãƒˆã‚’ {REPORT_FILENAME} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        except Exception as e:
            print(f"ğŸš¨ ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

    # --- 4. ãƒãƒ£ãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™ ---

    def _prepare_chart_data(self, df: pd.DataFrame) -> List[Dict[str, Any]]:
        """
        ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®ãƒãƒ£ãƒ¼ãƒˆè¡¨ç¤ºç”¨ã«ã€éå»æ•°ãƒ¶æœˆé–“ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã™ã€‚
        """
        # éå»180æ—¥åˆ†ã«çµã‚‹ (ãƒãƒ£ãƒ¼ãƒˆãŒé‡ããªã‚Šã™ããªã„ã‚ˆã†ã«)
        chart_df = df.iloc[-180:].copy() 
        
        # äºˆæ¸¬ãƒã‚¤ãƒ³ãƒˆã‚’ãƒãƒ£ãƒ¼ãƒˆã«è¿½åŠ ã™ã‚‹ãŸã‚ã«ã€äºˆæ¸¬æ—¥ã‚’è¨ˆç®—
        # äºˆæ¸¬ã¯ã€Œæœ€æ–°ãƒ‡ãƒ¼ã‚¿ã®æ—¥ä»˜ + HORIZONæ—¥å¾Œã€ã¨ã™ã‚‹
        latest_date = chart_df.index[-1]
        prediction_date = latest_date + timedelta(days=HORIZON)

        # äºˆæ¸¬ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ ã™ã‚‹ãŸã‚ã®ãƒ€ãƒŸãƒ¼è¡Œã‚’ä½œæˆ
        # ãƒãƒ£ãƒ¼ãƒˆãŒäºˆæ¸¬ãƒã‚¤ãƒ³ãƒˆã¾ã§ç·šã§ã¤ãªãŒã‚‹ã‚ˆã†ã«ã€æœ€æ–°ã®çµ‚å€¤ã‚’äºˆæ¸¬æ—¥ã®1æ—¥å‰ã«ã‚‚è¿½åŠ 
        
        # 1. æœ€å¾Œã®å®Ÿç¸¾æ—¥
        last_real_entry = {
            "date": latest_date.strftime('%Y-%m-%d'),
            "close": round(chart_df['Close'].iloc[-1], 2),
            "type": "Actual"
        }
        
        # 2. äºˆæ¸¬æ—¥ (å€¤ã¯äºˆæ¸¬æ™‚ã«æ›¸ãè¾¼ã¾ã‚Œã‚‹ãŸã‚ã€ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ã¨ã—ã¦ä¿æŒ)
        # NOTE: äºˆæ¸¬å€¤ã¯äºˆæ¸¬é–¢æ•°ãŒè¨ˆç®—ã™ã‚‹ãŸã‚ã€ã“ã“ã§ã¯æ§‹é€ ã®ã¿æº–å‚™
        
        # éå»ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰å¿…è¦ãªåˆ—ã ã‘ã‚’æŠ½å‡ºã—ã€JSONå½¢å¼ã®ãƒªã‚¹ãƒˆã«å¤‰æ›
        chart_list = []
        for index, row in chart_df.iterrows():
            chart_list.append({
                "date": index.strftime('%Y-%m-%d'),
                "close": round(row['Close'], 2),
                "type": "Actual"
            })
            
        # æœ€å¾Œã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã‚’è¿½åŠ 
        # (ãƒªã‚¹ãƒˆã®æœ€å¾Œã«å®Ÿéš›ã®äºˆæ¸¬å€¤ã‚’è¿½åŠ ã™ã‚‹å‡¦ç†ã¯ predict_and_report ã®å¤–éƒ¨ã§è¡Œã†ã‹ã€
        # ã“ã“ã§ã¯éå»ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’è¿”ã—ã¦ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã§å‡¦ç†ã™ã‚‹æ–¹ãŒã‚·ãƒ³ãƒ—ãƒ«)
        
        # ã‚·ãƒ³ãƒ—ãƒ«ã«éå»å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’è¿”ã™
        return chart_list

# --- å®Ÿè¡Œã«å¿…è¦ãªãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ ---

if __name__ == '__main__':
    # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå˜ç‹¬ã§å®Ÿè¡Œã•ã‚ŒãŸå ´åˆã«ã€ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã™ã‚‹
    # ã“ã‚Œã¯ã€ã‚¢ãƒ—ãƒªå®Ÿè¡Œå‰ã« `fallback_data.csv` ãŒå­˜åœ¨ã—ãªã„å ´åˆã«å½¹ç«‹ã¡ã¾ã™ã€‚
    
    if not os.path.exists(FALLBACK_FILENAME):
        print(f"ğŸ› ï¸ {FALLBACK_FILENAME} ãŒè¦‹ã¤ã‹ã‚‰ãªã„ãŸã‚ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã™ã€‚")
        
        days_to_generate = 1000
        start_date = datetime.now() - timedelta(days=days_to_generate)
        date_range = pd.date_range(start=start_date, periods=days_to_generate, freq='D')
        
        # S&P 500ã¾ãŸã¯ä¸»è¦å…ˆç‰©ã®å‹•ãã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
        # ãƒ©ãƒ³ãƒ€ãƒ ã‚¦ã‚©ãƒ¼ã‚¯ã«ãƒˆãƒ¬ãƒ³ãƒ‰ã¨ãƒã‚¤ã‚ºã‚’åŠ ãˆã‚‹
        np.random.seed(42)
        base_price = 4000
        returns = np.random.normal(0.0005, 0.01, days_to_generate)
        prices = base_price * (1 + returns).cumprod()
        volumes = np.random.randint(50000, 150000, days_to_generate)
        
        fallback_df = pd.DataFrame({
            'Date': date_range,
            'Close': prices.round(2),
            'Volume': volumes
        }).set_index('Date')
        
        fallback_df.to_csv(FALLBACK_FILENAME)
        print(f"âœ… {FALLBACK_FILENAME} ã« {len(fallback_df)} æ—¥åˆ†ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆã—ã¾ã—ãŸã€‚")
    
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    bot = FuturesMLBot()
    
    # ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾— (APIå¤±æ•—ã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã™ã‚‹å¯èƒ½æ€§ã‚ã‚Š)
    test_df = bot.fetch_ohlcv_data(DAYS_LOOKBACK)

    if not test_df.empty:
        # ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã¨ä¿å­˜
        bot.train_and_save_model(test_df)
        
        # é«˜åº¦ãªæŒ‡æ¨™ã®å–å¾—
        advanced = bot.fetch_advanced_metrics()
        
        # äºˆæ¸¬ã¨ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ
        bot.predict_and_report(test_df, advanced)
